{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install femr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import femr\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using APLUS ML with STARR OMOP\n",
    "\n",
    "This tutorial shows how to load STARR OMOP data into APLUS ML.\n",
    "\n",
    "It uses the [FEMR Python package](https://github.com/som-shahlab/femr) to load the STARR OMOP dataset (i.e. we assume you already have a FEMR extract prepared, if not please refer to the FEMR repo itself for instructions).\n",
    "\n",
    "Then, we create a dataframe of patient features and labels.\n",
    "\n",
    "Finally, we saves the dataframe to a CSV in the same format as expected in the corresponding APLUS ML tutorial `pad.ipynb`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PAD cohort from STARR-OMOP using FEMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FEMR patient database\n",
    "path_to_femr_extract: str = '/local-scratch/nigam/projects/ethanid/som-rit-phi-starr-prod.starr_omop_cdm5_deid_2023_02_08_extract_v8_no_observation'\n",
    "femr_database = femr.PatientDatabase(path_to_femr_extract)\n",
    "ontology = femr_database.get_ontology()\n",
    "print(\"# of patients in our database: \", len(femr_database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FEMR patient cohort using a custom Labeler\n",
    "from femr.labelers.omop import OMOPConceptCodeLabeler, get_outpatient_visit_codes\n",
    "from femr.labelers.core import TimeHorizon\n",
    "\n",
    "class PADLabeler(OMOPConceptCodeLabeler):\n",
    "    original_omop_concept_codes_pad: List[str] = [\n",
    "        \"ICD9/250.7\", \"ICD9/440.0\", \"ICD9/440.2\", \"ICD9/440.3\", \"ICD9/443.9\", \n",
    "        \"ICD9/444.22\", \"ICD9/444.8\", \"ICD9/445.02\", \"ICD9/447.1\", \"ICD10/E08.51\", \n",
    "        \"ICD10/E08.52\", \"ICD10/E10.5\", \"ICD10/E11.5\", \"ICD10/E13.5\", \"ICD10/I70.0\", \n",
    "        \"ICD10/I70.2\", \"ICD10/I70.3\", \"ICD10/I70.4\", \"ICD10/I70.5\", \"ICD10/I70.6\", \n",
    "        \"ICD10/I70.7\", \"ICD10/I70.9\", \"ICD10/I73.9\", \"ICD10/I74\", \"ICD10/I75.0\", \"ICD10/I77.1\",\n",
    "    ]\n",
    "\n",
    "# Identify patients with PAD\n",
    "prediction_codes = get_outpatient_visit_codes()\n",
    "time_horizon = TimeHorizon(0, None)\n",
    "labeler = PADLabeler(ontology, time_horizon, prediction_codes)\n",
    "# NOTE: This line takes a while to run on the full 100% STARR-OMOP extract\n",
    "labeled_patients = labeler.apply(\n",
    "    path_to_patient_database=path_to_femr_extract,\n",
    "    num_threads=20,\n",
    ")\n",
    "pickle.dump(labeled_patients, open('labeled_patients.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format dataset for APLUS ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_patients = pickle.load(open('labeled_patients.pkl', 'rb'))\n",
    "patients: List[Dict] = []\n",
    "\n",
    "for patient_id, labels in labeled_patients.items():\n",
    "    for label in labels:\n",
    "        patient_age_at_visit: datetime.timedelta = label.time - femr_database[patient_id].events[0].start\n",
    "        # Filter out patients < 50 years old\n",
    "        if patient_age_at_visit < datetime.timedelta(days=365*50):\n",
    "            continue\n",
    "        patients.append({\n",
    "            'id' : patient_id,\n",
    "            'y' : label.value,\n",
    "            'visit_datetime' : label.time,\n",
    "            'birth_datetime' : femr_database[patient_id].events[0].start,\n",
    "            'x_1' : len(femr_database[patient_id].events),\n",
    "            'x_2' : label.time - femr_database[patient_id].events[0].start,\n",
    "        })\n",
    "\n",
    "# Create patients\n",
    "df = pd.DataFrame(patients)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('./ignore/secure/femr_pad_inputs.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run patients through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load patients\n",
    "df = pd.read_csv('./ignore/secure/femr_pad_inputs.csv')\n",
    "\n",
    "# Run simple logistic regression on features to get model predictions\n",
    "X = df[['x_1', 'x_2']]\n",
    "y = df['y']\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "clf = LogisticRegression(random_state=0).fit(train_X, train_Y)\n",
    "y_hat = clf.predict_proba(train_Y)\n",
    "\n",
    "# Model predictions\n",
    "df['y_hat'] = y_hat\n",
    "\n",
    "# ABI test prediction\n",
    "df['abi_test_pred'] = np.random.normal(0.65 * df['y'] + (1 - df['y']) * 1.09, 0.15 * df['y'] + (1 - df['y']) * 0.11)\n",
    "\n",
    "# Random patient-level resource priority\n",
    "df['random_resource_priority'] = np.random.choice(range(df.shape[0]), replace=False, size=df.shape[0])\n",
    "\n",
    "pd.to_csv('./ignore/secure/femr_pad_inputs.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run APLUS ML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `pad.ipynb` notebook, feeding `./ignore/secure/femr_pad_inputs.csv` as the input CSV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
